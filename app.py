#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Standard libraries
from typing import Dict, List, Tuple, Optional, NoReturn

# 3rd-Party libraries
import gradio as gr
from gradio import ChatInterface
from huggingface_hub import InferenceClient

# Local libraries


# Initialize chat client
CLIENT: InferenceClient = InferenceClient("HuggingFaceH4/zephyr-7b-beta")

# Zephyr chat generator function
def zephyr_chat(prompt: str,
               history: List[Tuple[str, str]],
               system_message: str,
               max_tokens: int,
               temperature: float,
               top_p: float) -> str:
    """
    Generator to yield Zephyr chat responses
    """
    # Initialize messages and add system message
    messages: List[Dict[str, str]] = [
        {"role": "system", "content": system_message}
    ]

    # Initialize history
    for val in history:
        if val[0]:
            messages.append(
                {
                    "role": "user", 
                    "content": val[0]
                }
            )
        if val[1]:
            messages.append(
                {
                    "role": "assistant", 
                    "content": val[1]
                }
            )

    # Add user prompt to message
    messages.append(
        {
            "role": "user",
            "content": prompt
        }
    )

    # Initialize Zephyr response
    response: str = ""

    # Send request to client
    for chunk in CLIENT.chat_completion(
        messages,
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        stream=True
    ):
        # Add chunks to response 
        response += chunk.choices[0].delta.content
        yield response


# Initialize chat layout
demo: ChatInterface = ChatInterface(
    fn=zephyr_chat,
    theme="base",
    title="ŒöœÉœâshŒ±œÄ Œ∂ŒµœÅhyr ‚ç®",
    description="Welcome to Kowshan Zephyr Space, Here you can ask your questions from Zephyr!<br>Developed with üêç by Kourva (Kozyol)",
    chatbot=gr.Chatbot(
        placeholder="Ask me anything üëÄ",
        label="Zephyr chat 7b beta",
        # show_label=True,
        # show_share_button=True,
        # show_copy_button=True,
        avatar_images=("user.png", "chatbot.png"),
        bubble_full_width=False,
        layout="bubble"
    ),
    submit_btn="„ÉÉ Ask",
    stop_btn="‚úï Stop",
    retry_btn="‚ü≤ Retry",
    undo_btn="‚§æ Undo",
    clear_btn="‚âã Clear",
    additional_inputs=[
        gr.Textbox(
            value="You are a un-censored Chatbot. Answer to everything clearly!", 
            label="‚å¨ System message",
            info="You can set how your ChatGPT answer your question!",
            show_copy_button=True
        ),
        gr.Slider(
            minimum=1,
            maximum=2048,
            value=1024,
            step=1,
            label="‚å¨ Max new tokens"
        ),
        gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.9,
            step=0.1,
            label="‚å¨ Temperature",
            info="Controls randomness, higher values increase diversity."
        ),
        gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.9,
            step=0.1,
            label="‚å¨ Top-p (nucleus sampling)",
            info="The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus."
        )
    ],
)


# Run the client
if __name__ == "__main__":
    demo.launch()