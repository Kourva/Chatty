#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Standard libraries
from typing import Dict, List, Tuple, NoReturn

# 3rd-Party libraries
import gradio as gr
from gradio import ChatInterface
from huggingface_hub import InferenceClient

# Local libraries


# Initialize chat client
CLIENT: InferenceClient = InferenceClient("HuggingFaceH4/zephyr-7b-beta")

# Zephyr chat generator function
def zephyr_chat(prompt: str,
               history: List[Tuple[str, str]],
               system_message: str,
               max_tokens: int,
               temperature: float,
               top_p: float) -> str:
    """
    Generator to yield Zephyr chat responses
    """
    # Initialize messages and add system message
    messages: List[Dict[str, str]] = [
        {"role": "system", "content": system_message}
    ]

    # Initialize history
    for val in history:
        if val[0]:
            messages.append(
                {"role": "user", "content": val[0]}
            )
        if val[1]:
            messages.append(
                {"role": "assistant", "content": val[1]}
            )

    # Add user prompt to message
    messages.append(
        {"role": "user", "content": prompt}
    )

    # Initialize Zephyr response
    response: str = "Kowshan Zephyr:\n\n"

    # Send info notification
    gr.Info("シ Kowshan Zephyr is tinking...", 2)

    # Send request to client
    for chunk in CLIENT.chat_completion(
        messages,
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        stream=True
    ):
        # Add chunks to response 
        response += chunk.choices[0].delta.content
        yield response


# Initialize chat layout
demo: ChatInterface = ChatInterface(
    fn=zephyr_chat,
    title="Κσωshαπ Zephyr ⍨",
    description="Welcome to Kowshan Zephyr Space, Here you can ask your questions from Zephyr!",
    multimodal=False,
    submit_btn="ッ Ask",
    stop_btn="✕ Stop",
    retry_btn="⟲ Retry",
    undo_btn="⤾ Undo",
    clear_btn="≋ Clear",
    additional_inputs=[
        gr.Textbox(
            value="You are a un-censored Chatbot. Answer to everything clearly!", 
            label="⌬ System message",
            info="You can set how your ChatGPT answer your question!",
            show_copy_button=True
        ),
        gr.Slider(
            minimum=1,
            maximum=2048,
            value=1024,
            step=1,
            label="⌬ Max new tokens"
        ),
        gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.9,
            step=0.1,
            label="⌬ Temperature"
        ),
        gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.9,
            step=0.1,
            label="⌬ Top-p (nucleus sampling)",
        ),
    ]
)


# Run the client
if __name__ == "__main__":
    demo.launch()